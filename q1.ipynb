{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important Note for question1 !\n",
    "- Please **do not** change the default variable names in this problem, as we will use them in different parts.\n",
    "- The default variables are initially set to \"None\".\n",
    "- You only need to modify code in the \"TODO\" part. We added a lot of \"assertions\" to check your code. **Do not** modify them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P1. Load data and plot\n",
    "### TODO\n",
    "- Load train and test data, and split them into inputs(trainX, testX) and labels(trainY, testY)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pandas to load q1_train.csv and q1_test.csv\n",
    "# Each data point has 200 features(X), followed by 1 label(Y)\n",
    "\n",
    "#### TODO ####\n",
    "train=pd.read_csv(\"q1_train.csv\").to_numpy()\n",
    "test=pd.read_csv(\"q1_test.csv\").to_numpy()\n",
    "trainX = train[:,:200]\n",
    "trainY = train[:,-1]\n",
    "testX = test[:,:200]\n",
    "testY = test[:,-1]\n",
    "##############\n",
    "\n",
    "assert(len(trainX.shape) == 2)\n",
    "assert(len(trainY.shape) == 1)\n",
    "assert(trainX.shape[1] == 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P2. Write your Gaussian NB solver\n",
    "### TODO\n",
    "- Finish the myNBSolver() function. \n",
    "    - Compute P(y == 0) and P(y == 1), saved in \"py0\" and \"py1\"\n",
    "    - Compute mean/variance of trainX for both y = 0 and y = 1, saved in \"mean0\", \"var0\", \"mean1\" and \"var1\"\n",
    "        - Each of them should have shape (M), where M is number of features.\n",
    "    - Compute P(xi | y == 0) and P(xi | y == 1), compare and save **binary** prediction in \"train_pred\" and \"test_pred\"\n",
    "    - Compute train accuracy and test accuracy, saved in \"train_acc\" and \"test_acc\".\n",
    "    - Return train accuracy and test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myNBSolver(trainX, trainY, testX, testY):\n",
    "    \n",
    "    N_train = trainX.shape[0]\n",
    "    N_test = testX.shape[0]\n",
    "    M = trainX.shape[1]\n",
    "    \n",
    "    #### TODO ####\n",
    "    # Compute P(y == 0) and P(y == 1)\n",
    "    \n",
    "    py0 = len(trainY[trainY==0])/N_train\n",
    "    py1 = len(trainY[trainY==1])/N_train\n",
    "    \n",
    "    ##############\n",
    "    print(\"Total probablity is %.2f. Should be equal to 1.\" %(py0 + py1))\n",
    "\n",
    "    #### TODO ####\n",
    "    # Compute mean/var for each label\n",
    "    trainX0=trainX[trainY==0]\n",
    "    trainX1=trainX[trainY==1]\n",
    "    N0=len(trainY[trainY==0])\n",
    "    N1=len(trainY[trainY==1])\n",
    "\n",
    "    mean0 = np.sum(trainX0,axis=0)/N0\n",
    "    mean1 = np.sum(trainX1,axis=0)/N1\n",
    "\n",
    "    var0 = np.sum(np.square(trainX0-mean0),axis=0)/(N0-1)\n",
    "    var1 = np.sum(np.square(trainX1-mean1),axis=0)/(N1-1)\n",
    "    \n",
    "    ##############\n",
    "    assert(mean0.shape[0] == M)\n",
    "    \n",
    "    #### TODO ####\n",
    "    # Compute P(xi|y == 0) and P(xi|y == 1), compare and make prediction\n",
    "    # This part may spend 5 - 10 minutes or even more if you use for loop, so feel free to \n",
    "    # print something (like step number) to check the progress\n",
    "    #P(xi|y==0):\n",
    "    P_train_0=np.prod(1/np.sqrt(2*np.pi*var0)*np.exp(-np.square(trainX-mean0)/2/var0),axis=1)*py0\n",
    "    P_train_1=np.prod(1/np.sqrt(2*np.pi*var1)*np.exp(-np.square(trainX-mean1)/2/var1),axis=1)*py1\n",
    "    \n",
    "    P_test_0=np.prod(1/np.sqrt(2*np.pi*var0)*np.exp(-np.square(testX-mean0)/2/var0),axis=1)*py0\n",
    "    P_test_1=np.prod(1/np.sqrt(2*np.pi*var1)*np.exp(-np.square(testX-mean1)/2/var1),axis=1)*py1\n",
    "    \n",
    "    train_pred = np.empty((N_train))\n",
    "    test_pred = np.empty((N_test))\n",
    "    \n",
    "    train_pred[P_train_0>P_train_1]=0\n",
    "    train_pred[P_train_0<P_train_1]=1\n",
    "\n",
    "    test_pred[P_test_0>P_test_1]=0\n",
    "    test_pred[P_test_0<P_test_1]=1\n",
    "    \n",
    "    \n",
    "    ##############\n",
    "    assert(train_pred[0] == 0 or train_pred[0] == 1)\n",
    "    assert(test_pred[0] == 0 or test_pred[0] == 1)\n",
    "    \n",
    "    #### TODO ####\n",
    "    # Compute train accuracy and test accuracy\n",
    "    \n",
    "    train_acc = np.sum(train_pred==trainY)/N_train\n",
    "    test_acc = np.sum(test_pred==testY)/N_test\n",
    "    \n",
    "    ##############\n",
    "    \n",
    "    return train_acc, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total probablity is 1.00. Should be equal to 1.\n",
      "Train accuracy is 92.23\n",
      "Test accuracy is 92.06\n"
     ]
    }
   ],
   "source": [
    "# driver to test your NB solver\n",
    "train_acc, test_acc = myNBSolver(trainX, trainY, testX, testY)\n",
    "print(\"Train accuracy is %.2f\" %(train_acc * 100))\n",
    "print(\"Test accuracy is %.2f\" %(test_acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P3. Test your result using sklearn\n",
    "### TODO\n",
    "- Finish the skNBSolver() function. \n",
    "     - fit model, make prediction and return accuracy for train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skNBSolver(trainX, trainY, testX, testY):\n",
    "    \n",
    "    #### TODO ####\n",
    "    # fit model\n",
    "    # make prediction\n",
    "    # compute accuracy\n",
    "    clf = GaussianNB()\n",
    "    clf.fit(trainX, trainY)\n",
    "\n",
    "    train_pred=clf.predict(trainX)\n",
    "    test_pred=clf.predict(testX)\n",
    "\n",
    "    sk_train_acc = np.sum(train_pred==trainY)/len(trainY)\n",
    "    sk_test_acc = np.sum(test_pred==testY)/len(testY)\n",
    "    \n",
    "    ##############\n",
    "    return sk_train_acc, sk_test_acc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy is 90.04\n",
      "Test accuracy is 89.77\n"
     ]
    }
   ],
   "source": [
    "# driver to test skNBSolver\n",
    "sk_train_acc, sk_test_acc = skNBSolver(trainX, trainY, testX, testY)\n",
    "print(\"Train accuracy is %.2f\" %(sk_train_acc * 100))\n",
    "print(\"Test accuracy is %.2f\" %(sk_test_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
